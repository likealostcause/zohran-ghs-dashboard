{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "874d26d5",
   "metadata": {},
   "source": [
    "# Join Processed Data to School Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a54a3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "schools = gpd.read_file('../data/processed_data/school_points_with_lcgms.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcfd530",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "schools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde7687f",
   "metadata": {},
   "source": [
    "## Join Boroughs\n",
    "\n",
    "Lost borough names at an earlier stage so just going to bring them back in here via spatial join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18243f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "boroughs = gpd.read_file('../data/raw_data/NYC Planning/nybb_25c/nybb.shp')[['BoroName', 'geometry']].to_crs(schools.crs)\n",
    "master_schools = gpd.sjoin(schools, boroughs, how='left', predicate='within').drop(columns=['index_right'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c87b3e3",
   "metadata": {},
   "source": [
    "## Join DACs to Schools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6319efba",
   "metadata": {},
   "outputs": [],
   "source": [
    "dacs = gpd.read_file('../data/processed_data/dac_nyc_lite.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752efe16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that there aren't any public schools exactly on the border of a DAC\n",
    "assert schools.geometry.apply(dacs.union_all().covers).sum() == schools.geometry.within(dacs.union_all()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc0cdcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_schools = gpd.sjoin(schools, dacs, how='left', predicate='within')\n",
    "master_schools.drop(columns=['index_right', 'county', 'geoid'], inplace=True)\n",
    "master_schools['dac_designation'] = master_schools['dac_designation'].fillna(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61f03d2",
   "metadata": {},
   "source": [
    "## Join Election Results to Schools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a9ac0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_results = gpd.read_file('../data/processed_data/zohran_first_round_frac.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cadcb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproject to planar CRS Web Mercator (EPSG:3857) for accurate distance calculations\n",
    "master_schools_og_crs = master_schools.crs\n",
    "primary_results_og_crs = primary_results.crs\n",
    "master_schools = master_schools.to_crs('EPSG:3857')\n",
    "primary_results = primary_results.to_crs('EPSG:3857')\n",
    "\n",
    "# First do regular spatial join\n",
    "master_schools = gpd.sjoin(master_schools, primary_results, how='left', predicate='within').drop(columns=['index_right'])\n",
    "\n",
    "# Find unmatched schools\n",
    "unmatched_mask = master_schools['ZohranFirstRoundFrac'].isna()\n",
    "unmatched_schools = master_schools[unmatched_mask].copy()\n",
    "\n",
    "print(f\"Found {unmatched_mask.sum()} schools without polygon matches, using nearest neighbor...\")\n",
    "\n",
    "# Use sjoin_nearest for unmatched schools\n",
    "nearest_join = gpd.tools.sjoin_nearest(unmatched_schools.drop(columns='ZohranFirstRoundFrac'), primary_results, how='left')\n",
    "master_schools.loc[unmatched_mask, 'ZohranFirstRoundFrac'] = nearest_join['ZohranFirstRoundFrac'].values\n",
    "\n",
    "assert not master_schools['ZohranFirstRoundFrac'].isna().any()\n",
    "\n",
    "# Reproject back to original CRS\n",
    "master_schools = master_schools.to_crs(master_schools_og_crs)\n",
    "primary_results = primary_results.to_crs(primary_results_og_crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557056bf",
   "metadata": {},
   "source": [
    "## Join IBO School Barriers Data\n",
    "\n",
    "This dataset has capacity/utilization, percentage of space with A/C, building accessibility, and some other really cool fields, and they're all already joined to location code. So hoping this will join well\n",
    "\n",
    "NOTE: looks like IBO only included schools that were in all of the datasets they were joining (i.e. inner join for every join). This means if we go to the source data and do left joins instead, we might get better results. See footnotes on data sources [here](https://www.ibo.nyc.gov/content/publications/2025-march-barriers-to-learning-age-accessibility-space-usage-and-air-conditioning-in-nyc-school-buildings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc306d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: go back and get the original sources of all the data in IBO dataset to see if we can get better coverage.\n",
    "ibo_barriers = pd.read_excel('../data/raw_data/IBO/IBO-barriers-to-learning-data-file.xlsx', sheet_name='DATA')\n",
    "# NOTE: there are only 1309 records in IBO data. \n",
    "print(\"Pct match from IBO to master_schools:\", ibo_barriers['building_code'].isin(master_schools['Bldg_Code']).sum() / len(ibo_barriers))\n",
    "\n",
    "ibo_barriers['central_ac'] = ibo_barriers['central_ac'].map({'Y': 1, 'N': 0})\n",
    "\n",
    "ibo_cols_of_interest = [\n",
    "    'building_code',\n",
    "    'building_ownership_description',\n",
    "    'yearbuilt',\n",
    "    'age',\n",
    "    'bap_rating',\n",
    "    'Accessibility_Description',\n",
    "    'bldg_enroll',\n",
    "    'target_bldg_cap',\n",
    "    'utilization',\n",
    "    'overutilized',\n",
    "    'per_area_PHYS_ED',\n",
    "    'central_ac',\n",
    "    'per_ac_area_total',\n",
    "]\n",
    "ibo_barriers = ibo_barriers[ibo_cols_of_interest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbbf3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_schools = master_schools.merge(ibo_barriers, left_on='Bldg_Code', right_on='building_code', how='left').drop(columns=['building_code'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b989a321",
   "metadata": {},
   "source": [
    "## Join City Council Districts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb13bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "council_districts = gpd.read_file('../data/processed_data/city_council_districts.geojson').to_crs(master_schools.crs)\n",
    "master_schools = gpd.sjoin(master_schools, council_districts, how='left', predicate='within').drop(columns=['index_right', 'BOROUGH', 'Shape_Leng', 'Shape_Area'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c912c43",
   "metadata": {},
   "source": [
    "# Export Joined Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eaf2529",
   "metadata": {},
   "source": [
    "## Shorten Columns for Shapefile Limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e3c455",
   "metadata": {},
   "outputs": [],
   "source": [
    "shortened_cols = {\n",
    "    # DAC columns\n",
    "    'dac_designation': 'in_dac',\n",
    "    'combined_score': 'comb_score',\n",
    "    'percentile_rank_combined_nyc': 'pctl_comb',\n",
    "    'burden_score': 'burd_score',\n",
    "    'burden_score_percentile': 'pctl_burd',\n",
    "    'vulnerability_score': 'vuln_score',\n",
    "    'vulnerability_score_percentile': 'pctl_vuln',\n",
    "    # Primary results columns\n",
    "    'ZohranFirstRoundFrac': 'ZohrPrimR1',\n",
    "    # IBO columns\n",
    "    'age': 'Bldg_Age',\n",
    "    'building_ownership_description': 'Bldg_Owner',\n",
    "    'bldg_enroll': 'BldgEnroll',\n",
    "    'target_bldg_cap': 'BldgCapac',\n",
    "    'utilization': 'Util',\n",
    "    'overutilized': 'Overutil',\n",
    "    'Accessibility_Description': 'Accessible',\n",
    "    'per_area_PHYS_ED': 'PctAreaPE',\n",
    "    'per_ac_area_total': 'PctAreaAC',\n",
    "    # Council District columns\n",
    "    'NAME': 'CouncName',\n",
    "    'POLITICAL PARTY': 'CouncParty',\n",
    "    'DISTRICT OFFICE ADDRESS': 'CouncAddr',\n",
    "    'DISTRICT OFFICE PHONE': 'CouncPhone'\n",
    "}\n",
    "\n",
    "\n",
    "# test if cols are correct length\n",
    "for col in master_schools.rename(columns=shortened_cols).columns:\n",
    "    if len(col) > 10:\n",
    "        print(f\"{col} too long: currently {len(col)} chars\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2691eff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns for Shapefile\n",
    "master_schools = master_schools.rename(columns=shortened_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ce64ba",
   "metadata": {},
   "source": [
    "## Export to Shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a84572a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "# Save shapefile first\n",
    "shp_path = '../data/processed_data/master_schools.shp'\n",
    "master_schools.sort_values('Loc_Code').to_file(\n",
    "    shp_path,\n",
    "    driver='ESRI Shapefile'\n",
    ")\n",
    "\n",
    "# Create zip file with all shapefile components\n",
    "zip_path = '../data/processed_data/master_schools.zip'\n",
    "base_name = '../data/processed_data/master_schools'\n",
    "\n",
    "# Shapefile extensions to include\n",
    "extensions = ['.shp', '.shx', '.dbf', '.prj', '.cpg']\n",
    "\n",
    "with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "    for ext in extensions:\n",
    "        file_path = base_name + ext\n",
    "        if os.path.exists(file_path):\n",
    "            # Add file to zip with just the filename (no path)\n",
    "            zipf.write(file_path, os.path.basename(file_path))\n",
    "            print(f\"Added {os.path.basename(file_path)} to zip\")\n",
    "\n",
    "print(f\"Shapefile saved as zip: {zip_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c089bae7",
   "metadata": {},
   "source": [
    "## Export to GeoJSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d2009d",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_schools.sort_values('Loc_Code').to_file(\n",
    "    '../data/processed_data/master_schools.geojson', driver='GeoJSON'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.venv) zohran-ghs-dashboard",
   "language": "python",
   "name": "zohran-ghs-dashboard"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
