{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c17a0f7",
   "metadata": {},
   "source": [
    "# School Locations Processing\n",
    "We have 3 different files with school location information, and each file has slightly different contents. Need to compare contents and resolve what our final/true list of geo-locatable schools is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8acf19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ea58fa",
   "metadata": {},
   "source": [
    "## Load Raw Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a3c5a9",
   "metadata": {},
   "source": [
    "### School Point Locations\n",
    "Data source: https://data.cityofnewyork.us/Education/School-Point-Locations/jfju-ynrr/about_data\n",
    "\n",
    "Last updated: November 26, 2024\n",
    "\n",
    "Annoyingly, the data dictionary on the above linked page doesn't match the data itself, so we're left to guess on the meaning of some of these fields. Also, the description on the above linked page says this data contains Address, Principal, and Principal contact info, but that isn't in here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111c3f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "school_points_gdf = gpd.read_file('../data/raw_data/DOE/School Locations/School Point Locations/SchoolPoints_APS_2024_08_28/SchoolPoints_APS_2024_08_28.shp')\n",
    "school_points_gdf.rename(columns={'Location_C': 'Location Code', 'Name': 'Location Name'}, inplace=True)\n",
    "school_points_gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bfb28c2",
   "metadata": {},
   "source": [
    "### LCGMS\n",
    "Last updated: November 26, 2024\n",
    "\n",
    "This data has more robust fields in it related to grades, address, open date, principal contact info, etc. But there is a discrepancy in the records included in the geocoded vs. non-geocoded files. Not sure yet if there are any other discrepancies between these two files but need to figure that out."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd7eea9",
   "metadata": {},
   "source": [
    "#### Non-geocoded LCGMS data\n",
    "Source: https://www.nycenet.edu/PublicApps/LCGMS.aspx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30047234",
   "metadata": {},
   "outputs": [],
   "source": [
    "lcgms_df = pd.read_excel('../data/raw_data/DOE/School Locations/LCGMS/LCGMS_SchoolData_20250806_0112.xlsx', dtype=str, engine='openpyxl')\n",
    "lcgms_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2be48c9",
   "metadata": {},
   "source": [
    "#### Geocoded LCGMS data\n",
    "Source: https://data.cityofnewyork.us/Education/NYC-DOE-Public-School-Location-Information/3bkj-34v2/about_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0bd4df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lcgms_geocoded_df = pd.read_csv('../data/raw_data/DOE/School Locations/LCGMS/LCGMS_SchoolData_additional_geocoded_fields_added_.csv', encoding='latin-1')\n",
    "lcgms_geocoded_df\n",
    "# lcgms_geocoded_gdf = gpd.GeoDataFrame(lcgms_geocoded_df, geometry=gpd.GeoSeries.from_xy(lcgms_geocoded_df['lon'], lcgms_geocoded_df['lat']), crs=4326)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f2d399",
   "metadata": {},
   "source": [
    "## Investigate Discrepancies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d5f20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: need to somehow summarize for our non-technical folks how/that there are discrepances between these datasets so they can maybe run those down by emailing DOE officials or something. Wouldn't want us suggesting fake schools to the Z campaign or something weird like that.\n",
    "# Maybe they can also just do a manual fact-check on the records that are different between datasets?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60750679",
   "metadata": {},
   "source": [
    "### School Points vs. LCGMS non-geocoded\n",
    "\n",
    "The non-geocoded LCGMS data seems like it is the more \"official\" data compared to School Points and geocoded LCGMS, due to it being the spreadsheet downloaded from following links on the official LCGMS page [here](https://infohub.nyced.org/in-our-schools/operations/lcgms) rather than being sort of a sneaky extra dataset included on NYC open data (i.e. the geocoded one) or a poorly documented Shapefile on NYC Open Data. So, I think it makes sense to trust/prefer the non-geocoded LCGMS data over the geocoded data and attempt to map the non-geocoded LCGMS data somehow. The easiest way to do that would be to attach it to the school points layer, but we need to figure out how doable that is first (i.e. discrepancies in that potential join)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c50801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show columns that are in both school_points_gdf and lcgms_df\n",
    "school_points_gdf.columns.intersection(lcgms_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece1075a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show instances where Location Name is different between school_points_gdf and lcgms_df\n",
    "school_points_gdf[['Location Code', 'Location Name']].merge(\n",
    "    lcgms_df[['Location Code', 'Location Name']],\n",
    "    on='Location Code',\n",
    "    how='inner',\n",
    "    suffixes=('_school', '_lcgms')\n",
    ").query('`Location Name_school` != `Location Name_lcgms`')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3007e9",
   "metadata": {},
   "source": [
    "#### How many LCGMS records are NOT in School Points? (i.e. `set(LCGMS).difference(set(School Points))`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5dd8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show records that are NOT in school points but ARE in LCGMS\n",
    "lcgms_records_missing_from_school_points = school_points_gdf[['Location Code', 'Location Name']].merge(\n",
    "    lcgms_df[['Location Code', 'Location Name']],\n",
    "    on='Location Code',\n",
    "    how='outer',\n",
    "    suffixes=('_school_points', '_lcgms'),\n",
    "    indicator=True\n",
    ").query('_merge == \"right_only\"')\n",
    "print(\"Total records in LCGMS that are NOT in School Points:\", len(lcgms_records_missing_from_school_points))\n",
    "lcgms_records_missing_from_school_points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5496da75",
   "metadata": {},
   "source": [
    "Check if we can find the LCGMS records that are missing from School Points in geocoded LCGMS instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d182d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Welp, only 1 of the LCGMS records that are missing from school points are actually in the geocoded LCGMS data, but the lat/lon for that record is missing in geocoded LCGMS as well. So we won't have a use for geocoded LCGMS.\n",
    "# TODO: have someone on our team research these 17 schools we can't map\n",
    "lcgms_records_missing_from_school_points.drop(columns=['_merge']).merge(\n",
    "    lcgms_geocoded_df[['Location Code', 'Location Name', 'Latitude', 'Longitude']],\n",
    "    on='Location Code',\n",
    "    how='left',\n",
    "    suffixes=('_missing_from_school_points', '_geocoded'),\n",
    "    indicator=True\n",
    ").query('_merge == \"both\"')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3982e3d4",
   "metadata": {},
   "source": [
    "#### How many School Points records are NOT in LCGMS? (i.e. `set(School Points).difference(set(LCGMS))`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4219f0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "school_points_records_missing_from_lcgms = school_points_gdf[['Location Code', 'Location Name']].merge(\n",
    "    lcgms_geocoded_df[['Location Code', 'Location Name']],\n",
    "    on='Location Code',\n",
    "    how='outer',\n",
    "    suffixes=('_school_points', '_lcgms'),\n",
    "    indicator=True\n",
    ").query('_merge == \"left_only\"')\n",
    "print(\"Total records in School Points that are NOT in LCGMS:\", len(school_points_records_missing_from_lcgms))\n",
    "school_points_records_missing_from_lcgms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593fff45",
   "metadata": {},
   "source": [
    "Check if we can find the School Points records that are missing from LCGMS in geocoded LCGMS instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b116771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# phewf - no records from geocoded LCGMS that would have to be added to school points even after joining non-geocoded LCGMS onto school points.\n",
    "school_points_records_missing_from_lcgms.drop(columns=['_merge']).merge(\n",
    "    lcgms_geocoded_df[['Location Code', 'Location Name']],\n",
    "    on='Location Code',\n",
    "    how='left',\n",
    "    suffixes=('_missing_from_lcgms', '_geocoded'),\n",
    "    indicator=True\n",
    ").query('_merge == \"both\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4b740b",
   "metadata": {},
   "source": [
    "#### Are there any records in geocoded LCGMS that are NOT in the joined result of non-geocoded LCGMS + School Points?\n",
    "\n",
    "Thankfully, no."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7e1a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show records that are in geocoded LCGMS but NOT in the joined result of non-geocoded LCGMS + School Points\n",
    "school_points_gdf.merge(\n",
    "    lcgms_df[['Location Code', 'Location Name']],\n",
    "    on='Location Code',\n",
    "    how='outer',\n",
    ").merge(\n",
    "    lcgms_geocoded_df[['Location Code', 'Location Name']],\n",
    "    on='Location Code',\n",
    "    how='left',\n",
    "    suffixes=('', '_geocoded'),\n",
    "    indicator=True\n",
    ").query('_merge == \"right_only\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e7fe2c",
   "metadata": {},
   "source": [
    "### LCGMS non-geocoded vs. LCGMS geocoded\n",
    "\n",
    "The TL;DR here is that the delta between these two datasets is really befuddling, especially since it seems the geocoded one should be the exact same as the non-geocoded one but for additional lat/lon fields. I don't know the rhyme nor reason for these discrepancies, and so I think we should just prefer/trust the more official-looking one wherever possible, which is the non-geocoded LCGMS.\n",
    "\n",
    "Would love for the civil servants who made these datasets to explain why they are different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2f6732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE from LCGMS data dict: \"LOCATION CODE: a unique identifier that can include schools, administrative offices, learning communities, etc.  When the Learning_Community_Name = ‘School’, the Location_Code is a combination of the borough code and the school number.\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c551e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show fields that are in lcgms_geocoded_df but NOT in lcgms_df\n",
    "lcgms_geocoded_df.columns.difference(lcgms_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cf022e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show fields that are in lcgms_df but NOT in lcgms_geocoded_df\n",
    "lcgms_df.columns.difference(lcgms_geocoded_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eaeca5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare data in shared columns between lcgms_df and lcgms_geocoded_df\n",
    "shared_columns = set(lcgms_df.columns).intersection(set(lcgms_geocoded_df.columns))\n",
    "print(f\"Shared columns: {sorted(shared_columns)}\")\n",
    "\n",
    "# Merge the dataframes on Location Code to compare shared columns\n",
    "comparison_df = lcgms_df.merge(\n",
    "    lcgms_geocoded_df, \n",
    "    on='Location Code', \n",
    "    how='inner', \n",
    "    suffixes=('_non_geocoded', '_geocoded')\n",
    ")\n",
    "\n",
    "# Check for differences in each shared column (excluding Location Code which is the join key)\n",
    "shared_data_columns = [col for col in shared_columns if col != 'Location Code']\n",
    "differences_summary = {}\n",
    "\n",
    "for col in shared_data_columns:\n",
    "    col_non_geo = f\"{col}_non_geocoded\"\n",
    "    col_geo = f\"{col}_geocoded\"\n",
    "    \n",
    "    # Count records where values differ (handling NaN values)\n",
    "    different_mask = (\n",
    "        (comparison_df[col_non_geo].fillna('') != comparison_df[col_geo].fillna('')) |\n",
    "        (comparison_df[col_non_geo].isna() != comparison_df[col_geo].isna())\n",
    "    )\n",
    "    \n",
    "    num_differences = different_mask.sum()\n",
    "    differences_summary[col] = num_differences\n",
    "    \n",
    "    if num_differences > 0:\n",
    "        print(f\"\\n{col}: {num_differences} differences found\")\n",
    "        # Show first few examples of differences\n",
    "        # diff_examples = comparison_df[different_mask][['Location Code', col_non_geo, col_geo]].head()\n",
    "        # print(diff_examples)\n",
    "\n",
    "# print(f\"\\nSummary of differences:\")\n",
    "# for col, count in differences_summary.items():\n",
    "#     print(f\"{col}: {count} differences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0308e888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show records where Location Code matches but Location Name does not match\n",
    "lcgms_df[['Location Code', 'Location Name']].merge(\n",
    "    lcgms_geocoded_df[['Location Code', 'Location Name']], \n",
    "    on='Location Code', \n",
    "    how='inner', \n",
    "    suffixes=('_non-geocoded', '_geocoded')\n",
    ").query('`Location Name_non-geocoded` != `Location Name_geocoded`')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54626312",
   "metadata": {},
   "source": [
    "## Join Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d50b1f",
   "metadata": {},
   "source": [
    "Show that there's no difference in joining by Location Code vs. ATS System Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d97384",
   "metadata": {},
   "outputs": [],
   "source": [
    "ats_count = len(school_points_gdf.merge(lcgms_df, left_on='ATS', right_on='ATS System Code', how='inner'))\n",
    "loc_count = len(school_points_gdf.merge(lcgms_df, on='Location Code', how='inner'))\n",
    "assert ats_count == loc_count, f\"ATS join: {ats_count} records, Location Code join: {loc_count} records\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67ded85",
   "metadata": {},
   "source": [
    "### Outer Join LCGMS with School Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a770f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For our final school points data (at least for now), join LCGMS onto school points\n",
    "school_points_with_lcgms = school_points_gdf.merge(\n",
    "    lcgms_df,\n",
    "    on='Location Code',\n",
    "    how='outer',\n",
    "    suffixes=('_school_points', '_lcgms'),\n",
    "    indicator=True\n",
    ")\n",
    "\n",
    "# Keep a column that indicates whether the record is missing from LCGMS or not so we can select just LCGMS records if we find out that the school points data is outdated or inaccurate compared to LCGMS.\n",
    "school_points_with_lcgms.rename(columns={'_merge': 'in_LCGMS'}, inplace=True)\n",
    "school_points_with_lcgms['in_LCGMS'] = school_points_with_lcgms['in_LCGMS'].str.contains('both|right_only')\n",
    "\n",
    "school_points_with_lcgms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7043ece9",
   "metadata": {},
   "source": [
    "# Clean Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1712cc92",
   "metadata": {},
   "source": [
    "## Cleaning up specific fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b0c6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "school_points_with_lcgms['Open Date'] = pd.to_datetime(school_points_with_lcgms['Open Date'], format='%b %d %Y', errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b12d0f",
   "metadata": {},
   "source": [
    "### Coalesce `Location Name` from School Points and LCGMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b977b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "school_points_with_lcgms['Location Name'] = school_points_with_lcgms['Location Name_lcgms'].fillna(school_points_with_lcgms['Location Name_school_points'])\n",
    "school_points_with_lcgms.drop(columns=['Location Name_lcgms', 'Location Name_school_points'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9678658",
   "metadata": {},
   "source": [
    "### Coalesce `ATS System Code` from School Points and LCGMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33dab731",
   "metadata": {},
   "outputs": [],
   "source": [
    "school_points_with_lcgms['ATS'] = school_points_with_lcgms['ATS'].fillna(school_points_with_lcgms['ATS System Code'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81810840",
   "metadata": {},
   "source": [
    "Building Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038f7d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: not sure why we have disagreements between Building Code and Building_C. Seems likely that one is more up-to-date than the other, and likely LCGMS is more up-to-date, but haven't verified.\n",
    "school_points_with_lcgms[\n",
    "    (school_points_with_lcgms['Building_C'] != school_points_with_lcgms['Building Code'])\n",
    "    & school_points_with_lcgms['Building Code'].notna()\n",
    "    & school_points_with_lcgms['Building_C'].notna()\n",
    "][['Location Code', 'Location Name', 'Building Code', 'Building_C', 'in_LCGMS']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fb9dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For now, we're going to keep the Building Code from LCGMS unless NaN\n",
    "school_points_with_lcgms['Building Code'] = school_points_with_lcgms['Building Code'\n",
    "                                                                     ].fillna(school_points_with_lcgms['Building_C'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60826b81",
   "metadata": {},
   "source": [
    "Address Fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbb815c",
   "metadata": {},
   "outputs": [],
   "source": [
    "school_points_with_lcgms.rename(columns={'State Code': 'State'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f6664c",
   "metadata": {},
   "outputs": [],
   "source": [
    "address_fields = ['Primary Address', 'City', 'State', 'Zip']\n",
    "school_points_with_lcgms.loc[:, address_fields] = school_points_with_lcgms[address_fields].apply(lambda x: x.str.strip().str.upper())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63ee4f3",
   "metadata": {},
   "source": [
    "### Drop Unnecessary Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5006b3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: need to go through all the LCGMS columns and figure out which ones we can drop\n",
    "# Drop unnecessary columns\n",
    "cols_to_drop = [\n",
    "    'ATS System Code', # Duplicate of ATS column\n",
    "    'Geographic', # This is from School Points and I have no idea what it means.\n",
    "    'Building_C',  # This is the Building Code from School Point, which is duplicate\n",
    "    'Status Description', # These are all either \"Open\" or NaN, so not useful\n",
    "]\n",
    "\n",
    "# All the \"HighSchool\" columns are null\n",
    "cols_to_drop += [x for x in school_points_with_lcgms.columns if 'HighSchool' in x]\n",
    "school_points_with_lcgms.drop(columns=cols_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d4cbb0",
   "metadata": {},
   "source": [
    "Reorder columns for readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6519a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "core_cols = ['Location Name', 'Managed By Name', 'Location Code', 'Building Code', 'ATS', 'Primary Address', 'City', 'State', 'Zip', 'Borough Block Lot', 'Census Tract', 'Community District', 'Council District']\n",
    "school_points_with_lcgms = school_points_with_lcgms[core_cols + [col for col in school_points_with_lcgms.columns if not col in core_cols]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c344ba4d",
   "metadata": {},
   "source": [
    "## Identify DOE and Charter Schools that weren't in LCGMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef562af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the points that don't join to LCGMS, filter out ones that have \"charter\" in the name and add the \"Managed By Name\" as \"Charter\" for non-LCGMS records\n",
    "additional_charter_mask = (\n",
    "    school_points_with_lcgms['Managed By Name'].isna() \n",
    "    & \n",
    "    (school_points_with_lcgms['Location Name'].fillna('').str.contains('charter', case=False))\n",
    ")\n",
    "school_points_with_lcgms.loc[additional_charter_mask, 'Managed By Name'] = 'Charter'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6414e309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the points that don't join to LCGMS, set \"Managed By Name\" as \"DOE\" if meets a few DOE-related regex patterns\n",
    "additional_doe_mask = (\n",
    "    school_points_with_lcgms['Managed By Name'].isna() \n",
    "    & \n",
    "    # ALC=\"Alternative Learning Center\", \"YABC\"=\"Young Adult Borough Center\", District 79 is for alternative schools\n",
    "    school_points_with_lcgms['Location Name'].fillna('').str.contains(r'[PMH]\\.S\\.|ALC|YABC|District 79|D79', regex=True)\n",
    ")\n",
    "school_points_with_lcgms.loc[additional_doe_mask, 'Managed By Name'] = 'DOE'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f6cbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: have someone manually look over these remaining schools with no DOE/Charter category and categorize them\n",
    "print(\"Schools without DOE/Charter category:\", len(school_points_with_lcgms[school_points_with_lcgms['Managed By Name'].isna()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcd7f9a",
   "metadata": {},
   "source": [
    "# Duplicate geometries\n",
    "\n",
    "Nearly HALF of the school points are duplicated locations. This means we don't end up seeing half of the points on the map because they're on top of each other.\n",
    "\n",
    "A lot of these appear to be different schools that share the same address, even if the building they're in is different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5654e0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Almost HALF the data is duplicate geometries. (almost no difference when dealing with lat/lon -- two more duplicates when looking at lat/lon)\n",
    "print('Count of records with duplicate geometry:', school_points_with_lcgms['geometry'].duplicated(keep=False).sum())\n",
    "print('Proportion of records with duplicate geometry:', school_points_with_lcgms['geometry'].duplicated(keep=False).sum() / len(school_points_with_lcgms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2143b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slightly less when looking at address but still nearly half duplicated\n",
    "print('Count of records with duplicate address:', school_points_with_lcgms['Primary Address'].duplicated(keep=False).sum())\n",
    "print('Proportion of records with duplicate address:', school_points_with_lcgms['Primary Address'].duplicated(keep=False).sum() / len(school_points_with_lcgms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfa865b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find where geometry is duplicated but address within duplicate group is different\n",
    "school_points_with_lcgms.groupby('geometry').filter(lambda g: g['Primary Address'].nunique() > 1).sort_values(['geometry', 'Primary Address'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cba9230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ok at least with these 3 examples, they all appear to just be different schools that \n",
    "# share an address:\n",
    "#    - CSI High School for International Studies\n",
    "#    - Gaynor McCown Expeditionary Learning School\n",
    "#    - Marsh Avenue School for Expeditionary Learning\n",
    "school_points_with_lcgms[\n",
    "    (school_points_with_lcgms.duplicated(subset=['geometry'], keep=False))\n",
    "    & school_points_with_lcgms['geometry'].notna()\n",
    "    ].sort_values(by='geometry')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5224b0",
   "metadata": {},
   "source": [
    "# Geocoding\n",
    "\n",
    "For now, we're geocoding all addresses from the either of the following scenarios:\n",
    "- Records from LCGMS that didn't join onto School Points and thus have no geometry or lat/lon\n",
    "- Records that have a duplicate geometry\n",
    "\n",
    "\n",
    "It's potentially useful to geocode all the data -- both addresses and school names -- to compare the results to what's in school points and ensure accuracy. But for now we're not going down that route."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51acbd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: don't mess with how the `full_address` column is created. Geocoding idempotency relies on it being formatted exactly the same as it is here to prevent unnecessary Google Maps API calls.\n",
    "# Create a full_address column for geocoding\n",
    "school_points_with_lcgms.loc[school_points_with_lcgms['Primary Address'].notnull(), 'full_address'] =(\n",
    "        school_points_with_lcgms['Primary Address'].fillna('') + ', ' +\n",
    "        school_points_with_lcgms['City'].fillna('') + ', ' +\n",
    "        school_points_with_lcgms['State'].fillna('') + ' ' +\n",
    "        school_points_with_lcgms['Zip'].fillna('')\n",
    "    ).str.strip(', ').replace(r', $', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca24180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show how many addresses we have and what the duplicate breakdown is\n",
    "missing_addresses = school_points_with_lcgms['Primary Address'].isna().sum()\n",
    "non_null_addresses = len(school_points_with_lcgms) - missing_addresses\n",
    "unique_addresses = school_points_with_lcgms['Primary Address'].nunique()\n",
    "\n",
    "# Let's get the value counts to understand the distribution\n",
    "address_counts = school_points_with_lcgms['Primary Address'].value_counts()\n",
    "\n",
    "# How many addresses appear exactly once?\n",
    "addresses_appearing_once = (address_counts == 1).sum()\n",
    "print(f\"Addresses that appear exactly once: {addresses_appearing_once}\")\n",
    "\n",
    "# How many addresses appear more than once?\n",
    "addresses_appearing_multiple = (address_counts > 1).sum() \n",
    "print(f\"Addresses that appear multiple times: {addresses_appearing_multiple}\")\n",
    "\n",
    "# Total records with those duplicate addresses\n",
    "records_with_duplicate_addresses = address_counts[address_counts > 1].sum()\n",
    "print(f\"Total records that have duplicate addresses: {records_with_duplicate_addresses}\")\n",
    "\n",
    "print(f\"Check: {addresses_appearing_once} + {addresses_appearing_multiple} should equal {unique_addresses}\")\n",
    "print(f\"Check: {addresses_appearing_once} + {records_with_duplicate_addresses} should equal {non_null_addresses}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d777520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: for now, we're going to geocode all addresses associated with a duplicate geometry or no geometry at all.\n",
    "# Addresses with no geometry at all\n",
    "no_geometry_addresses = school_points_with_lcgms[school_points_with_lcgms['geometry'].isna()]['full_address'].dropna().unique().tolist()\n",
    "# Addresses associated with a duplicate geometry\n",
    "dupe_geometry_addresses = school_points_with_lcgms[\n",
    "    (school_points_with_lcgms['geometry'].duplicated(keep=False))\n",
    "]['full_address'].drop_duplicates().dropna().tolist()\n",
    "\n",
    "addresses_to_geocode = list(set(no_geometry_addresses + dupe_geometry_addresses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0ebb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import googlemaps\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "cache_file = '../data/google_maps_geocode_cache.json'\n",
    "if os.path.exists(cache_file):\n",
    "    with open(cache_file, 'r', encoding='utf-8') as f:\n",
    "        cached_geocodes = json.load(f)\n",
    "else:\n",
    "    cached_geocodes = {}\n",
    "\n",
    "# Get API key from environment variable\n",
    "api_key = os.getenv('GOOGLE_MAPS_API_KEY')\n",
    "if not api_key:\n",
    "    raise ValueError(\"GOOGLE_MAPS_API_KEY not found in environment variables. Please check your .env file.\")\n",
    "\n",
    "gmaps = googlemaps.Client(key=api_key)\n",
    "\n",
    "for i, address in enumerate(addresses_to_geocode):\n",
    "    if address in cached_geocodes:\n",
    "        #print(f\"{address} found in cache.\")\n",
    "        continue\n",
    "    print(f\"Geocoding {i+1}/{len(addresses_to_geocode)}: {address}\")\n",
    "    result = gmaps.geocode(address)\n",
    "    cached_geocodes[address] = result[0]\n",
    "    \n",
    "    # Save cache periodically (every 10 geocodes) and at the end\n",
    "    if (i + 1) % 10 == 0 or i == len(addresses_to_geocode) - 1:\n",
    "        with open(cache_file, 'w+', encoding='utf-8') as f:\n",
    "            json.dump(cached_geocodes, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    # Current rate limit is 3K per minute, which we should be well under\n",
    "    # if i < len(addresses_to_geocode) - 1:  # Don't delay after last request\n",
    "    #     time.sleep(.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899a587d",
   "metadata": {},
   "outputs": [],
   "source": [
    "geocodes_data = []\n",
    "for full_address, geocode_result in cached_geocodes.items():\n",
    "    row = {\n",
    "        'full_address': full_address,\n",
    "        'google_lat': geocode_result.get('geometry', {}).get('location', {}).get('lat', None),\n",
    "        'google_lng': geocode_result.get('geometry', {}).get('location', {}).get('lng', None),\n",
    "        'google_location_type': geocode_result.get('geometry', {}).get('location_type', None)\n",
    "    }\n",
    "    geocodes_data.append(row)\n",
    "geocodes_df = pd.DataFrame(geocodes_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be82ea19",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Count of records with duplicate geometry BEFORE GEOCODING:', school_points_with_lcgms['geometry'].duplicated(keep=False).sum())\n",
    "print('Proportion of records with duplicate geometry BEFORE GEOCODING:', school_points_with_lcgms['geometry'].duplicated(keep=False).sum() / len(school_points_with_lcgms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c10392",
   "metadata": {},
   "outputs": [],
   "source": [
    "school_points_with_lcgms = school_points_with_lcgms.merge(geocodes_df, on='full_address', how='left')\n",
    "school_points_with_lcgms['lat'] = school_points_with_lcgms['google_lat'].fillna(school_points_with_lcgms['Latitude'])\n",
    "school_points_with_lcgms['lng'] = school_points_with_lcgms['google_lng'].fillna(school_points_with_lcgms['Longitude'])\n",
    "school_points_with_lcgms.set_geometry(gpd.points_from_xy(school_points_with_lcgms['lng'], school_points_with_lcgms['lat']), crs='EPSG:4326', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba701b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Count of records with duplicate geometry AFTER GEOCODING:', school_points_with_lcgms['geometry'].duplicated(keep=False).sum())\n",
    "print('Proportion of records with duplicate geometry AFTER GEOCODING:', school_points_with_lcgms['geometry'].duplicated(keep=False).sum() / len(school_points_with_lcgms))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad039d6",
   "metadata": {},
   "source": [
    "# Post-Geocoding Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac779e3",
   "metadata": {},
   "source": [
    "## Remove Unnecessary Geocoding Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98801b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "geocode_cols_to_drop = ['Latitude', 'Longitude', 'google_lat', 'google_lng']\n",
    "school_points_with_lcgms.drop(columns=geocode_cols_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa7b367",
   "metadata": {},
   "source": [
    "## Remove non-NYC points\n",
    "\n",
    "We have 1 Long Island point that shows up after geocoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb86a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "school_points_with_lcgms = school_points_with_lcgms.clip(gpd.read_file('../data/raw_data/nybb_25c/nybb.shp').to_crs(school_points_with_lcgms.crs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37760e0",
   "metadata": {},
   "source": [
    "# Sanity Check: Visualize Data with Geopandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1a1d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "school_points_with_lcgms.explore(tiles='CartoDB positron',\n",
    "                popup=['Location Name', 'Community District', 'Council District',\n",
    "                       'Principal Name', 'Principal Title', 'Principal Phone Number'],\n",
    "                tooltip=['Location Name'],  # Show on hover\n",
    "                legend=True,\n",
    "                style_kwds={'fillOpacity': 0.7, 'weight': 1}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4022208d",
   "metadata": {},
   "source": [
    "# Export Data\n",
    "\n",
    "For now, we're manually uploading these files to Google Drive to avoid having to deal with Google Drive API keys or S3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e3e743",
   "metadata": {},
   "source": [
    "Must shorten columns to 10 chars to export to Shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308e95cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shorten fields to 10 characters or less for shapefile export\n",
    "short_col_map = {'Location Name': 'Loc_Name',\n",
    "    'Managed By Name': 'Managed_By',\n",
    "    'Location Code': 'Loc_Code',\n",
    "    'Building Code': 'Bldg_Code',\n",
    "    'ATS': 'ATS',\n",
    "    'Primary Address': 'Address',\n",
    "    'City': 'City',\n",
    "    'State': 'State',\n",
    "    'Zip': 'Zip',\n",
    "    'Borough Block Lot': 'BBL',\n",
    "    'Census Tract': 'C_Tract',\n",
    "    'Community District': 'Comm_Dist',\n",
    "    'Council District': 'Council_Di',\n",
    "    'geometry': 'geometry',\n",
    "    'BEDS Number': 'BEDS_Num',\n",
    "    'Location Type Description': 'Loc_Type_D',\n",
    "    'Location Category Description': 'Loc_Cat_D',\n",
    "    'Grades': 'Grades',\n",
    "    'Grades Final': 'Grades_Fin',\n",
    "    'Open Date': 'Open_Date',\n",
    "    'NTA': 'NTA',\n",
    "    'NTA_Name': 'NTA_Name',\n",
    "    'Principal Name': 'Princ_Name',\n",
    "    'Principal Title': 'Princ_Titl',\n",
    "    'Principal Phone Number': 'Princ_Phon',\n",
    "    'Fax Number': 'Fax_Num',\n",
    "    'Geographical District Code': 'GeoDisCode',\n",
    "    'Administrative District Code': 'AdDistCode',\n",
    "    'Administrative District Location Code': 'AdDistLocC',\n",
    "    'Administrative District Name': 'AdDistName',\n",
    "    'Community School Sup Name': 'ComScSupNa',\n",
    "    'BCO Location Code': 'BCOLocCode',\n",
    "    'in_LCGMS': 'in_LCGMS',\n",
    "    'full_address': 'full_addr',\n",
    "    'google_location_type': 'g_loc_type',\n",
    "    'lat': 'lat',\n",
    "    'lng': 'lng'\n",
    "}\n",
    "\n",
    "import zipfile\n",
    "import os\n",
    "# Save shapefile first\n",
    "shp_path = '../data/processed_data/school_points_with_lcgms.shp'\n",
    "school_points_with_lcgms.rename(columns=short_col_map).to_file(\n",
    "    shp_path,\n",
    "    driver='ESRI Shapefile'\n",
    ")\n",
    "\n",
    "# Create zip file with all shapefile components\n",
    "zip_path = '../data/processed_data/school_points_with_lcgms.zip'\n",
    "base_name = '../data/processed_data/school_points_with_lcgms'\n",
    "\n",
    "# Shapefile extensions to include\n",
    "extensions = ['.shp', '.shx', '.dbf', '.prj', '.cpg']\n",
    "\n",
    "with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "    for ext in extensions:\n",
    "        file_path = base_name + ext\n",
    "        if os.path.exists(file_path):\n",
    "            # Add file to zip with just the filename (no path)\n",
    "            zipf.write(file_path, os.path.basename(file_path))\n",
    "            print(f\"Added {os.path.basename(file_path)} to zip\")\n",
    "\n",
    "print(f\"Shapefile saved as zip: {zip_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c1d542",
   "metadata": {},
   "source": [
    "Export to GeoJSON for easier use when loading data into other Python scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d0d895",
   "metadata": {},
   "outputs": [],
   "source": [
    "school_points_with_lcgms.to_file(\n",
    "    '../data/processed_data/school_points_with_lcgms.geojson',\n",
    "      driver='GeoJSON'\n",
    "      )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.venv) zohran-ghs-dashboard",
   "language": "python",
   "name": "zohran-ghs-dashboard"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
